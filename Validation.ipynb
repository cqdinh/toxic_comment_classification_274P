{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from transformers import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from time import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import math\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 256])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_encoding_size = 256\n",
    "\n",
    "def position_embeddings(max_pos, size):\n",
    "    embeddings = np.zeros((max_pos, size))\n",
    "    w = 1 / (10000 ** (2*np.arange(size // 2 )/size))\n",
    "    for pos in range(max_pos):\n",
    "        embeddings[pos,0::2] = np.sin(w*pos)\n",
    "        embeddings[pos,1::2] = np.cos(w*pos)\n",
    "    return torch.Tensor(embeddings)\n",
    "    \n",
    "pos_embed = position_embeddings(10000, position_encoding_size)\n",
    "pos_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = BertModel.from_pretrained('bert-base-cased')\n",
    "\n",
    "bert_hidden_size = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, bert_size, position_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.attention = nn.Linear(bert_size + position_size, 1)\n",
    "        self.softmax = nn.Softmax(1)\n",
    "\n",
    "        self.prediction = nn.Sequential(\n",
    "            nn.Linear(bert_size, 1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(1024, 6),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    '''\n",
    "    embeddings: shape (segment count, 512, bert_hidden_size)\n",
    "    position_encodings:  shape (segment count, 512, position_encoding_size)\n",
    "    comment_bounds: Array of tuples of the form [(start, end)]. comment_bounds[i] = (a, b) indicates that comment i's embeddings can be extracted as embeddings[a:b]\n",
    "    '''\n",
    "    def forward(self, embeddings, position_encodings, comment_bounds = None):\n",
    "        attention_input = torch.cat([embeddings, position_encodings], dim=2) # (batch, 512, position_size + bert_hidden_size)\n",
    "\n",
    "        # (batch, 512, 1)\n",
    "        attentions = self.attention(attention_input)\n",
    "        if comment_bounds is None:\n",
    "            attentions = self.softmax(attentions) # (batch, 512, 1)\n",
    "            vecs = torch.sum(attentions * embeddings, dim=1) # (batch, bert_hidden_size)\n",
    "            return self.prediction(vecs) # (batch, 1)\n",
    "\n",
    "        vecs = []\n",
    "        for (a,b) in comment_bounds:\n",
    "            comment_embeddings = embeddings[a:b] # (segment_count, 512, bert_hidden_size)\n",
    "            comment_attentions = attentions[a:b] # (segment_count, 512, 1)\n",
    "            attention_weights = self.softmax(comment_attentions) # (segment_count, 512, 1)\n",
    "            weighted_embeddings = attention_weights * embeddings[a:b] # (segment_count, 512, bert_hidden_size)\n",
    "            vec = torch.sum(weighted_embeddings.view(-1, weighted_embeddings.shape[-1]), dim=0, keepdim=True) # (segment_count, bert_hidden_size)\n",
    "            vecs.append(vec)\n",
    "        return self.prediction(torch.cat(vecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, file_format, normalize):\n",
    "        super().__init__()\n",
    "\n",
    "        # Load the data from files\n",
    "        input_ids = torch.load(file_format.format(\"input_ids\"))\n",
    "        positions = torch.load(file_format.format(\"positions\"))\n",
    "        comment_ids = torch.load(file_format.format(\"ids\"))\n",
    "        targets = torch.load(file_format.format(\"targets\"))\n",
    "\n",
    "        # Treat the targets as binary to separate the possible outputs\n",
    "        target_ids = torch.sum(torch.Tensor([32, 16, 8, 4, 2, 1]) * targets, axis=1)\n",
    "\n",
    "        # Store the data according to the target. Useful for normalization\n",
    "        self.data = [[] for i in range(64)]\n",
    "\n",
    "        # Load the data into the array\n",
    "        curr_id = 0\n",
    "        start_index = 0\n",
    "        for i in range(comment_ids.shape[0]):\n",
    "            if comment_ids[i] != curr_id:\n",
    "                target_id = int(target_ids[curr_id].item())\n",
    "                data = (input_ids[start_index:i], positions[start_index:i], targets[curr_id])\n",
    "                self.data[target_id].append(data)\n",
    "\n",
    "                curr_id = comment_ids[i]\n",
    "                start_index = i\n",
    "\n",
    "        target_id = int(target_ids[curr_id].item())\n",
    "        data = (input_ids[start_index:i], positions[start_index:i], targets[curr_id])\n",
    "        self.data[target_id].append(data)\n",
    "\n",
    "        n_nontoxic = len(self.data[0])\n",
    "\n",
    "        n_of_each = n_nontoxic // (len(self.data)-1)\n",
    "\n",
    "        # Remove the empty arrays from the data\n",
    "        self.data = [data for data in self.data if data]\n",
    "\n",
    "        n_copies = np.array([1]+[n_of_each // len(self.data[i]) for i in range(1,len(self.data))])\n",
    "        \n",
    "        if not normalize:\n",
    "            n_copies = np.ones_like(n_copies)\n",
    "        \n",
    "        self.data_length = np.array([len(data) for data in self.data])\n",
    "\n",
    "        segment_lengths = n_copies*self.data_length\n",
    "\n",
    "        self.length = int(np.sum(segment_lengths))\n",
    "\n",
    "        self.boundaries = np.zeros(segment_lengths.shape[0]+1)\n",
    "        self.boundaries[1:] = np.cumsum(segment_lengths)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        for i in range(self.boundaries.shape[0] - 1):\n",
    "            if index >= self.boundaries[i] and index < self.boundaries[i+1]:\n",
    "                inner_index = int((index - self.boundaries[i]) % self.data_length[i])\n",
    "                return self.data[i][inner_index]\n",
    "        print(\"Index: \", index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153164"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = MyDataset(\"test_{}.pt\", False)\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterable(obj):\n",
    "    try:\n",
    "        iter(obj)\n",
    "    except Exception:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def collate_samples(batch):\n",
    "    for i, item in enumerate(batch):\n",
    "        if not iterable(item):\n",
    "            print(i, item)\n",
    "    split_comments, positions, targets = zip(*batch)\n",
    "    input_ids = []\n",
    "    comment_bounds = []\n",
    "    start = 0\n",
    "    for comment in split_comments:\n",
    "        input_ids += comment\n",
    "        comment_bounds.append((start, start+len(comment)))\n",
    "        start += len(comment)\n",
    "    input_ids = torch.stack(input_ids, dim=0)\n",
    "    encoded_positions = torch.cat([\n",
    "                          # Use the position array as indices into the position embedding\n",
    "                          pos_embed[position_arr]\n",
    "                          # For each comment in the batch\n",
    "                          for position_arr in positions                     \n",
    "                      ])\n",
    "  \n",
    "    targets = [target.view(1, -1) for target in targets]\n",
    "    targets = torch.cat(targets, dim=0)\n",
    "    comment_bounds = np.array(comment_bounds, dtype=np.int32)\n",
    "    return input_ids, encoded_positions, comment_bounds, targets\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "test = DataLoader(test_dataset, \n",
    "                   batch_size = batch_size,\n",
    "                   shuffle=True,\n",
    "                   collate_fn = collate_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([135, 512]) torch.Size([135, 512, 256]) (128, 2) torch.Size([128, 6])\n"
     ]
    }
   ],
   "source": [
    "for i, (input_ids, encoded_position, comment_bounds, target) in enumerate(test):\n",
    "    print(input_ids.shape, encoded_position.shape, comment_bounds.shape, target.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./model/model_{}.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_auc(pred, target):\n",
    "    result = []\n",
    "    for i in range(pred.shape[1]):\n",
    "        if len(np.unique(target[:,i])) == 2:\n",
    "            result.append(roc_auc_score(target[:,i], pred[:,i], labels=[0,1]))\n",
    "        else:\n",
    "            extra = np.array([1-target[0,i]])\n",
    "            target_i = np.concatenate((target[:,i], extra))\n",
    "            pred_i = np.concatenate((pred[:,i], extra))\n",
    "            result.append(roc_auc_score(target_i, pred_i, labels=[0,1]))\n",
    "            \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert.eval()\n",
    "device = torch.device(\"cuda:0\")\n",
    "bert = bert.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (attention): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       "  (prediction): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=1024, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=1024, out_features=6, bias=True)\n",
       "    (5): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Classifier(bert_hidden_size, position_encoding_size)\n",
    "model = model.to(device)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load = \"epoch_{:04d}_batch_{:04d}_bce_{:.04f}\".format(29, 100, 0.0629)\n",
    "\n",
    "if load is not None:\n",
    "    model.load_state_dict(torch.load(model_path.format(load)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpochLogger:\n",
    "    def __init__(self, path):\n",
    "        self.file = open(path, \"w\")\n",
    "    \n",
    "    def log(self, string):\n",
    "        print(string)\n",
    "        self.file.write(string)\n",
    "        self.file.write(\"\\n\")\n",
    "    \n",
    "    def close(self):\n",
    "        self.file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n",
      "Batch 00000/1197 (10421.4s remaining)\t \n",
      "\tAUC: Toxic: 0.7431 Severe Toxic: 0.9766 Obscene: 0.6976 Threat: 0.9805 Insult: 0.8013 Identity-based Hate: 0.9883\n",
      "\tAccuracy: Toxic: 0.8750 Severe Toxic: 0.9531 Obscene: 0.8828 Threat: 0.9609 Insult: 0.9297 Identity-based Hate: 0.9766\n",
      "Batch 00001/1197 ( 9962.4s remaining)\t \n",
      "\tAUC: Toxic: 0.7049 Severe Toxic: 0.9707 Obscene: 0.6263 Threat: 0.9804 Insult: 0.7602 Identity-based Hate: 0.9823\n",
      "\tAccuracy: Toxic: 0.8438 Severe Toxic: 0.9414 Obscene: 0.8438 Threat: 0.9609 Insult: 0.9141 Identity-based Hate: 0.9648\n",
      "Batch 00002/1197 ( 9998.9s remaining)\t \n",
      "\tAUC: Toxic: 0.7141 Severe Toxic: 0.9661 Obscene: 0.6791 Threat: 0.9817 Insult: 0.7048 Identity-based Hate: 0.9777\n",
      "\tAccuracy: Toxic: 0.8359 Severe Toxic: 0.9323 Obscene: 0.8490 Threat: 0.9635 Insult: 0.9010 Identity-based Hate: 0.9557\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-ab37259aae9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Get the outputs from the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_comments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_position\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomment_bounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m#print(output[0], target[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-7c710e116411>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, embeddings, position_encodings, comment_bounds)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mcomment_attentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattentions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# (segment_count, 512, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mattention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomment_attentions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (segment_count, 512, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mweighted_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_weights\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# (segment_count, 512, bert_hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweighted_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (segment_count, bert_hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mvecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "log_frequency = 1\n",
    "\n",
    "clear_frequency = 100\n",
    "\n",
    "log_path = \"./logs/val_output.txt\"\n",
    "\n",
    "epoch_times = []\n",
    "batch_times = []\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "logger = EpochLogger(log_path)\n",
    "predicted = None\n",
    "true = None\n",
    "n_correct = 0\n",
    "n_processed = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(\"Testing\")\n",
    "    predicted = None\n",
    "    for i, (input_ids, encoded_position, comment_bounds, target) in enumerate(test):\n",
    "        batch_start = time()\n",
    "        # Get the BERT output\n",
    "        encoded_comments = bert(input_ids.to(device))[0]\n",
    "\n",
    "        # Get the outputs from the network\n",
    "        output = model(encoded_comments, encoded_position.to(device), comment_bounds)\n",
    "\n",
    "        #print(output[0], target[0])\n",
    "        # Gradient descent\n",
    "        pred = torch.round(output.cpu().detach())\n",
    "        if predicted is None:\n",
    "            predicted = pred.clone()\n",
    "            true = target.clone()\n",
    "        else:\n",
    "            predicted = torch.cat((predicted, pred), dim=0)\n",
    "            true = torch.cat((true, target), dim=0)\n",
    "\n",
    "        n_correct += torch.sum(pred == target, axis=0).numpy()\n",
    "        n_processed += pred.shape[0]\n",
    "        \n",
    "        batch_times.append(time() - batch_start)\n",
    "\n",
    "        if i % log_frequency == 0:\n",
    "            logger.log(\"Batch {:05d}/{} ({:7.01f}s remaining)\\t \".format(i, len(test), np.mean(batch_times)*(len(test) - i)))\n",
    "            auc = calc_auc(predicted.numpy(), true.numpy())\n",
    "            logger.log(\"\\tAUC: Toxic: {:.04f} Severe Toxic: {:.04f} Obscene: {:.04f} Threat: {:.04f} Insult: {:.04f} Identity-based Hate: {:.04f}\".format(*auc))\n",
    "            acc = n_correct / n_processed\n",
    "            logger.log(\"\\tAccuracy: Toxic: {:.04f} Severe Toxic: {:.04f} Obscene: {:.04f} Threat: {:.04f} Insult: {:.04f} Identity-based Hate: {:.04f}\".format(*acc))\n",
    "\n",
    "        if i % clear_frequency == 0 and i != 0:\n",
    "            clear_output()\n",
    "\n",
    "    auc = calc_auc(predicted.numpy(), true.numpy())\n",
    "    acc = n_correct / n_processed\n",
    "    logger.log(\"Test Values:\")\n",
    "\n",
    "    logger.log(\"\\tAUC: Toxic: {:.04f} Severe Toxic: {:.04f} Obscene: {:.04f} Threat: {:.04f} Insult: {:.04f} Identity-based Hate: {:.04f}\".format(*auc))\n",
    "\n",
    "    logger.log(\"\\tAccuracy:  Toxic: {:.04f} Severe Toxic: {:.04f} Obscene: {:.04f} Threat: {:.04f} Insult: {:.04f} Identity-based Hate: {:.04f}\".format(*acc))\n",
    "logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153159</th>\n",
       "      <td>fffcd0960ee309b5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153160</th>\n",
       "      <td>fffd7a9a6eb32c16</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153161</th>\n",
       "      <td>fffda9e8d6fafa9e</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153162</th>\n",
       "      <td>fffe8f1340a79fc2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153163</th>\n",
       "      <td>ffffce3fb183ee80</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153164 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id  toxic  severe_toxic  obscene  threat  insult  \\\n",
       "0       00001cee341fdb12     -1            -1       -1      -1      -1   \n",
       "1       0000247867823ef7     -1            -1       -1      -1      -1   \n",
       "2       00013b17ad220c46     -1            -1       -1      -1      -1   \n",
       "3       00017563c3f7919a     -1            -1       -1      -1      -1   \n",
       "4       00017695ad8997eb     -1            -1       -1      -1      -1   \n",
       "...                  ...    ...           ...      ...     ...     ...   \n",
       "153159  fffcd0960ee309b5     -1            -1       -1      -1      -1   \n",
       "153160  fffd7a9a6eb32c16     -1            -1       -1      -1      -1   \n",
       "153161  fffda9e8d6fafa9e     -1            -1       -1      -1      -1   \n",
       "153162  fffe8f1340a79fc2     -1            -1       -1      -1      -1   \n",
       "153163  ffffce3fb183ee80     -1            -1       -1      -1      -1   \n",
       "\n",
       "        identity_hate  \n",
       "0                  -1  \n",
       "1                  -1  \n",
       "2                  -1  \n",
       "3                  -1  \n",
       "4                  -1  \n",
       "...               ...  \n",
       "153159             -1  \n",
       "153160             -1  \n",
       "153161             -1  \n",
       "153162             -1  \n",
       "153163             -1  \n",
       "\n",
       "[153164 rows x 7 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels = pd.read_csv(\"./test_labels.csv\")\n",
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 6])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153159</th>\n",
       "      <td>fffcd0960ee309b5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153160</th>\n",
       "      <td>fffd7a9a6eb32c16</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153161</th>\n",
       "      <td>fffda9e8d6fafa9e</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153162</th>\n",
       "      <td>fffe8f1340a79fc2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153163</th>\n",
       "      <td>ffffce3fb183ee80</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153164 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id  toxic  severe_toxic  obscene  threat  insult  \\\n",
       "0       00001cee341fdb12    0.0           0.0      0.0     0.0     0.0   \n",
       "1       0000247867823ef7   -1.0          -1.0     -1.0    -1.0    -1.0   \n",
       "2       00013b17ad220c46   -1.0          -1.0     -1.0    -1.0    -1.0   \n",
       "3       00017563c3f7919a   -1.0          -1.0     -1.0    -1.0    -1.0   \n",
       "4       00017695ad8997eb   -1.0          -1.0     -1.0    -1.0    -1.0   \n",
       "...                  ...    ...           ...      ...     ...     ...   \n",
       "153159  fffcd0960ee309b5   -1.0          -1.0     -1.0    -1.0    -1.0   \n",
       "153160  fffd7a9a6eb32c16   -1.0          -1.0     -1.0    -1.0    -1.0   \n",
       "153161  fffda9e8d6fafa9e   -1.0          -1.0     -1.0    -1.0    -1.0   \n",
       "153162  fffe8f1340a79fc2   -1.0          -1.0     -1.0    -1.0    -1.0   \n",
       "153163  ffffce3fb183ee80   -1.0          -1.0     -1.0    -1.0    -1.0   \n",
       "\n",
       "        identity_hate  \n",
       "0                 0.0  \n",
       "1                -1.0  \n",
       "2                -1.0  \n",
       "3                -1.0  \n",
       "4                -1.0  \n",
       "...               ...  \n",
       "153159           -1.0  \n",
       "153160           -1.0  \n",
       "153161           -1.0  \n",
       "153162           -1.0  \n",
       "153163           -1.0  \n",
       "\n",
       "[153164 rows x 7 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "test_labels[:,columns] = predicted.numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
